{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "projected_gradient_descent.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nowei/adversarial-dl/blob/master/projected_gradient_descent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOjcxt-MTkw5",
        "colab_type": "text"
      },
      "source": [
        "### This notebook is optionally accelerated with a GPU runtime.\n",
        "### If you would like to use this acceleration, please select the menu option \"Runtime\" -> \"Change runtime type\", select \"Hardware Accelerator\" -> \"GPU\" and click \"SAVE\"\n",
        "\n",
        "----------------------------------------------------------------------\n",
        "\n",
        "# ResNet\n",
        "\n",
        "*Author: Pytorch Team*\n",
        "\n",
        "**Deep residual networks pre-trained on ImageNet**\n",
        "\n",
        "<img src=\"https://pytorch.org/assets/images/resnet.png\" alt=\"alt\" width=\"50%\"/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpN_KNKuTkw7",
        "colab_type": "code",
        "outputId": "59c37003-22c8-4123-8779-226fb58780d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import torch\n",
        "# model = torch.hub.load('pytorch/vision:v0.4.2', 'resnet18', pretrained=True)\n",
        "# or any of these variants\n",
        "# model = torch.hub.load('pytorch/vision:v0.4.2', 'resnet34', pretrained=True)\n",
        "model = torch.hub.load('pytorch/vision:v0.4.2', 'resnet50', pretrained=True)\n",
        "# model = torch.hub.load('pytorch/vision:v0.4.2', 'resnet101', pretrained=True)\n",
        "# model = torch.hub.load('pytorch/vision:v0.4.2', 'resnet152', pretrained=True)\n",
        "model.eval()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/pytorch/vision/archive/v0.4.2.zip\" to /root/.cache/torch/hub/v0.4.2.zip\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/checkpoints/resnet50-19c8e357.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 153MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5o-n_QMqTkw_",
        "colab_type": "text"
      },
      "source": [
        "All pre-trained models expect input images normalized in the same way,\n",
        "i.e. mini-batches of 3-channel RGB images of shape `(3 x H x W)`, where `H` and `W` are expected to be at least `224`.\n",
        "The images have to be loaded in to a range of `[0, 1]` and then normalized using `mean = [0.485, 0.456, 0.406]`\n",
        "and `std = [0.229, 0.224, 0.225]`.\n",
        "\n",
        "Here's a sample execution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2Jzps2KabIp",
        "colab_type": "code",
        "outputId": "e26f8007-6b72-477c-b669-e4b54a6aa367",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!wget https://gist.githubusercontent.com/yrevar/942d3a0ac09ec9e5eb3a/raw/238f720ff059c1f82f368259d1ca4ffa5dd8f9f5/imagenet1000_clsidx_to_labels.txt\n",
        "with open('imagenet1000_clsidx_to_labels.txt', 'r') as f:\n",
        "    classes = eval(f.read())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-23 03:54:54--  https://gist.githubusercontent.com/yrevar/942d3a0ac09ec9e5eb3a/raw/238f720ff059c1f82f368259d1ca4ffa5dd8f9f5/imagenet1000_clsidx_to_labels.txt\n",
            "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 30564 (30K) [text/plain]\n",
            "Saving to: ‘imagenet1000_clsidx_to_labels.txt’\n",
            "\n",
            "\r          imagenet1   0%[                    ]       0  --.-KB/s               \rimagenet1000_clsidx 100%[===================>]  29.85K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2019-11-23 03:54:54 (2.43 MB/s) - ‘imagenet1000_clsidx_to_labels.txt’ saved [30564/30564]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvPfxRF8TkxA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download an example image from the pytorch website\n",
        "import urllib\n",
        "url, filename = (\"https://pbs.twimg.com/media/DzIyOyEWwAAOxWv.jpg\", \"dog.jpg\")\n",
        "try: urllib.URLopener().retrieve(url, filename)\n",
        "except: urllib.request.urlretrieve(url, filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDHln_HXT4q4",
        "colab_type": "code",
        "outputId": "8476d0b7-597d-4777-b234-68aaa8ec0c28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "from IPython.display import Image as imshow\n",
        "imshow(filename)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAUDBAQEAwUEBAQFBQUGBwwIBwcHBw8LCwkMEQ8SEhEP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\nsLe0PQKLrv7KdDpUNsCicofhHiPM4R4gZUrCBSd8ygruY/eIVOyNT3c//9k=\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6-82CGVTkxC",
        "colab_type": "code",
        "outputId": "5f31cdd9-62c4-4cf9-f3af-097718baa0e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# sample execution (requires torchvision)\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "input_image = Image.open(filename)\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "input_tensor = preprocess(input_image)\n",
        "data = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
        "\n",
        "def fgsm_attack(image, epsilon, data_graph):\n",
        "    sign_data_grad = data_grad.sign()\n",
        "    perturbed_image = image + epsilon*sign_data_grad\n",
        "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
        "    print('changed', torch.sum(epsilon*sign_data_grad))\n",
        "    return perturbed_image\n",
        "\n",
        "epsilon = 20/255\n",
        "target = torch.zeros(1,dtype=torch.long)\n",
        "target[0] = 1\n",
        "device = 'cuda'\n",
        "# move the input and model to GPU for speed if available\n",
        "if torch.cuda.is_available():\n",
        "    data = data.to(device)\n",
        "    model.to(device)\n",
        "    # Send the data and label to the device\n",
        "    target = target.to(device)\n",
        "\n",
        "    # Set requires_grad attribute of tensor. Important for Attack\n",
        "    data.requires_grad = True\n",
        "    \n",
        "    # Forward pass the data through the model\n",
        "    output = model(data)\n",
        "    init_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "    print(classes[init_pred.item()], torch.nn.functional.softmax(output[0], dim=0).max())\n",
        "    # Calculate the loss\n",
        "    loss = F.nll_loss(output, target)\n",
        "    \n",
        "    # Zero all existing gradients\n",
        "    model.zero_grad()\n",
        "\n",
        "    # Calculate gradients of model in backward pass\n",
        "    loss.backward()\n",
        "\n",
        "    # Collect datagrad\n",
        "    data_grad = data.grad.data\n",
        "\n",
        "    # Call FGSM Attack\n",
        "    perturbed_data = fgsm_attack(data, epsilon, data_grad)\n",
        "\n",
        "    # Re-classify the perturbed image\n",
        "    output = model(perturbed_data)\n",
        "    print('perturbedddddd')\n",
        "# with torch.no_grad():\n",
        "    # output = model(input_batch)\n",
        "# Tensor of shape 1000, with confidence scores over Imagenet's 1000 classes\n",
        "# The output has unnormalized scores. To get probabilities, you can run a softmax on it.\n",
        "probs = torch.nn.functional.softmax(output[0], dim=0)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "giant panda, panda, panda bear, coon bear, Ailuropoda melanoleuca tensor(0.8202, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "changed tensor(29.8039, device='cuda:0')\n",
            "perturbedddddd\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDIwjtaHTBKN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def proj_grad_desc(x, y, model, step_size, epsilon, steps=50, target=None):\n",
        "    adversary = x.clone().detach().requires_grad_(True).to(x.device)\n",
        "    max_diff = x + epsilon\n",
        "    min_diff = x - epsilon\n",
        "    for i in range(steps):\n",
        "        curr = adversary.clone().detach().requires_grad_(True).to(adversary.device)\n",
        "        output = model(curr)\n",
        "        loss = F.nll_loss(output, target if target else y)\n",
        "        loss.backward()\n",
        "        with torch.no_grad():\n",
        "            curr_grad = curr.grad * step_size \n",
        "            if target:\n",
        "                adversary -= curr_grad\n",
        "            else:\n",
        "                adversary += curr_grad\n",
        "        adversary = torch.max(torch.min(adversary, max_diff), min_diff)\n",
        "    return adversary.detach()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "be63gDP7tb0d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trans = transforms.ToPILImage()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gULvyrpt4anC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preprocess_2 = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "preprocess_3 = transforms.Compose([\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])                                   \n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8vJjNFcnQcp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "ecd926c0-90ff-4dd2-a72e-39f9d00d21bc"
      },
      "source": [
        "label = torch.tensor([388]).to(data.device)\n",
        "print(classes[label.item()])\n",
        "target = torch.tensor([368]).to(data.device)\n",
        "# target = None\n",
        "if target:\n",
        "    print(classes[target.item()])\n",
        "adv = proj_grad_desc(data, label, model, 0.01, 0.999 * 1/255, steps=50, target=target)\n",
        "# curr = preprocess_3(preprocess_2(input_image) + (data - adv).to('cpu'))\n",
        "# print(curr)\n",
        "# print(classes[model(curr.to(data.device)).argmax().item()])\n",
        "# trans(curr[0].to('cpu')).save('nani.jpg')\n",
        "trans(input_tensor.to('cpu')).save('nanie.jpg')\n",
        "result = model(adv)\n",
        "probs = torch.nn.functional.softmax(result[0], dim=0)\n",
        "print(classes[probs.argmax().item()], probs.max())\n",
        "trans(adv.to('cpu')[0]).save('pgd_doggo.jpg')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "giant panda, panda, panda bear, coon bear, Ailuropoda melanoleuca\n",
            "gibbon, Hylobates lar\n",
            "gibbon, Hylobates lar tensor(0.8041, device='cuda:0', grad_fn=<MaxBackward1>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h67FESc5UF2P",
        "colab_type": "code",
        "outputId": "19afc37d-4207-42d1-fd6d-17344e2c8d3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(classes[probs.argmax().item()])"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "poncho\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGl6XTOFZy6R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "local = trans(perturbed_data.to('cpu')[0])\n",
        "trans(data.to('cpu')[0]).save('orig_doggo.jpg')\n",
        "local.save('doggo.jpg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNo4N93YTkxG",
        "colab_type": "text"
      },
      "source": [
        "### Model Description\n",
        "\n",
        "Resnet models were proposed in \"Deep Residual Learning for Image Recognition\".\n",
        "Here we have the 5 versions of resnet models, which contains 5, 34, 50, 101, 152 layers respectively.\n",
        "Detailed model architectures can be found in Table 1.\n",
        "Their 1-crop error rates on imagenet dataset with pretrained models are listed below.\n",
        "\n",
        "| Model structure | Top-1 error | Top-5 error |\n",
        "| --------------- | ----------- | ----------- |\n",
        "|  resnet18       | 30.24       | 10.92       |\n",
        "|  resnet34       | 26.70       | 8.58        |\n",
        "|  resnet50       | 23.85       | 7.13        |\n",
        "|  resnet101      | 22.63       | 6.44        |\n",
        "|  resnet152      | 21.69       | 5.94        |\n",
        "\n",
        "### References\n",
        "\n",
        " - [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2o9Wa6DncMf4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}