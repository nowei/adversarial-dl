{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "projected_gradient_descent.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nowei/adversarial-dl/blob/master/projected_gradient_descent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOjcxt-MTkw5",
        "colab_type": "text"
      },
      "source": [
        "### This notebook is optionally accelerated with a GPU runtime.\n",
        "### If you would like to use this acceleration, please select the menu option \"Runtime\" -> \"Change runtime type\", select \"Hardware Accelerator\" -> \"GPU\" and click \"SAVE\"\n",
        "\n",
        "----------------------------------------------------------------------\n",
        "\n",
        "# ResNet\n",
        "\n",
        "*Author: Pytorch Team*\n",
        "\n",
        "**Deep residual networks pre-trained on ImageNet**\n",
        "\n",
        "<img src=\"https://pytorch.org/assets/images/resnet.png\" alt=\"alt\" width=\"50%\"/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpN_KNKuTkw7",
        "colab_type": "code",
        "outputId": "e452283a-487d-49c9-ab5a-95bbc1db3d29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import torch\n",
        "model = torch.hub.load('pytorch/vision:v0.4.2', 'resnet18', pretrained=True)\n",
        "# or any of these variants\n",
        "# model = torch.hub.load('pytorch/vision:v0.4.2', 'resnet34', pretrained=True)\n",
        "# model = torch.hub.load('pytorch/vision:v0.4.2', 'resnet50', pretrained=True)\n",
        "# model = torch.hub.load('pytorch/vision:v0.4.2', 'resnet101', pretrained=True)\n",
        "# model = torch.hub.load('pytorch/vision:v0.4.2', 'resnet152', pretrained=True)\n",
        "model.eval()"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.4.2\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5o-n_QMqTkw_",
        "colab_type": "text"
      },
      "source": [
        "All pre-trained models expect input images normalized in the same way,\n",
        "i.e. mini-batches of 3-channel RGB images of shape `(3 x H x W)`, where `H` and `W` are expected to be at least `224`.\n",
        "The images have to be loaded in to a range of `[0, 1]` and then normalized using `mean = [0.485, 0.456, 0.406]`\n",
        "and `std = [0.229, 0.224, 0.225]`.\n",
        "\n",
        "Here's a sample execution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2Jzps2KabIp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !wget https://gist.githubusercontent.com/yrevar/942d3a0ac09ec9e5eb3a/raw/238f720ff059c1f82f368259d1ca4ffa5dd8f9f5/imagenet1000_clsidx_to_labels.txt\n",
        "with open('imagenet1000_clsidx_to_labels.txt', 'r') as f:\n",
        "    classes = eval(f.read())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvPfxRF8TkxA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download an example image from the pytorch website\n",
        "import urllib\n",
        "url, filename = (\"https://pbs.twimg.com/media/DzIyOyEWwAAOxWv.jpg\", \"dog.jpg\")\n",
        "try: urllib.URLopener().retrieve(url, filename)\n",
        "except: urllib.request.urlretrieve(url, filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDHln_HXT4q4",
        "colab_type": "code",
        "outputId": "101e52da-85d6-4c76-b455-8a685269c1e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "from IPython.display import Image as imshow\n",
        "imshow(filename)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAUDBAQEAwUEBAQFBQUGBwwIBwcHBw8LCwkMEQ8SEhEP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\nsLe0PQKLrv7KdDpUNsCicofhHiPM4R4gZUrCBSd8ygruY/eIVOyNT3c//9k=\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gZqROFtOMMq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sample execution (requires torchvision)\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "device = 'cuda'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxo6wXXnCpRc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "input_image = Image.open(filename)\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "input_tensor = preprocess(input_image)\n",
        "data = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6-82CGVTkxC",
        "colab_type": "code",
        "outputId": "77fddbb3-e97a-4f78-aeb7-7e1a8ce5652d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "\n",
        "\n",
        "def fgsm_attack(image, epsilon, data_graph):\n",
        "    sign_data_grad = data_grad.sign()\n",
        "    perturbed_image = image + epsilon*sign_data_grad\n",
        "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
        "    print('changed', torch.sum(epsilon*sign_data_grad))\n",
        "    return perturbed_image\n",
        "\n",
        "epsilon = 20/255\n",
        "target = torch.zeros(1,dtype=torch.long)\n",
        "target[0] = 1\n",
        "device = 'cuda'\n",
        "# move the input and model to GPU for speed if available\n",
        "if torch.cuda.is_available():\n",
        "    data = data.to(device)\n",
        "    model.to(device)\n",
        "    # Send the data and label to the device\n",
        "    target = target.to(device)\n",
        "\n",
        "    # Set requires_grad attribute of tensor. Important for Attack\n",
        "    data.requires_grad = True\n",
        "    \n",
        "    # Forward pass the data through the model\n",
        "    output = model(data)\n",
        "    init_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "    print(classes[init_pred.item()], torch.nn.functional.softmax(output[0], dim=0).max())\n",
        "    # Calculate the loss\n",
        "    loss = F.nll_loss(output, target)\n",
        "    \n",
        "    # Zero all existing gradients\n",
        "    model.zero_grad()\n",
        "\n",
        "    # Calculate gradients of model in backward pass\n",
        "    loss.backward()\n",
        "\n",
        "    # Collect datagrad\n",
        "    data_grad = data.grad.data\n",
        "\n",
        "    # Call FGSM Attack\n",
        "    perturbed_data = fgsm_attack(data, epsilon, data_grad)\n",
        "\n",
        "    # Re-classify the perturbed image\n",
        "    output = model(perturbed_data)\n",
        "    print('perturbedddddd')\n",
        "# with torch.no_grad():\n",
        "    # output = model(input_batch)\n",
        "# Tensor of shape 1000, with confidence scores over Imagenet's 1000 classes\n",
        "# The output has unnormalized scores. To get probabilities, you can run a softmax on it.\n",
        "probs = torch.nn.functional.softmax(output[0], dim=0)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "giant panda, panda, panda bear, coon bear, Ailuropoda melanoleuca tensor(0.8202, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "changed tensor(30.9020, device='cuda:0')\n",
            "perturbedddddd\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "be63gDP7tb0d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trans = transforms.ToPILImage()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gULvyrpt4anC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preprocess_2 = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "preprocess_3 = transforms.Compose([\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])                                   \n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8vJjNFcnQcp",
        "colab_type": "code",
        "outputId": "2817f98b-740e-4e2b-dc0c-722c867389a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "source": [
        "label = torch.tensor([388]).to(data.device)\n",
        "print(classes[label.item()])\n",
        "target = torch.tensor([368]).to(data.device)\n",
        "# target = None\n",
        "if target:\n",
        "    print(classes[target.item()])\n",
        "adv = proj_grad_desc(data, label, model, 0.01, 4 * 1/255, steps=50, target=target)\n",
        "print('nani')\n",
        "# curr = preprocess_3(preprocess_2(input_image) + (data - adv).to('cpu'))\n",
        "# print(curr)\n",
        "# print(classes[model(curr.to(data.device)).argmax().item()])\n",
        "# trans(curr[0].to('cpu')).save('nani.jpg')\n",
        "trans(input_tensor.to('cpu')).save('nanie.jpg')\n",
        "result = model(adv)\n",
        "probs = torch.nn.functional.softmax(result[0], dim=0)\n",
        "adv[:, 0, :, :] = adv[:, 0, :, :] * 0.229 + 0.485\n",
        "adv[:, 1, :, :] = adv[:, 1, :, :] * 0.224 + 0.456\n",
        "adv[:, 2, :, :] = adv[:, 2, :, :] * 0.225 + 0.406\n",
        "print(classes[probs.argmax().item()], probs.max())\n",
        "trans(adv.to('cpu')[0]).save('pgd_doggo.jpg')\n",
        "adv[:, 0, :, :] = (adv[:, 0, :, :] - 0.485) / 0.229\n",
        "adv[:, 1, :, :] = (adv[:, 1, :, :] - 0.456) / 0.224 \n",
        "adv[:, 2, :, :] = (adv[:, 2, :, :] - 0.406) / 0.225\n",
        "# trans(adv.to('cpu')[0]).save('pgd_doggo.jpg')\n",
        "print(adv)\n",
        "result = model(adv)\n",
        "probs = torch.nn.functional.softmax(result[0], dim=0)\n",
        "print(classes[probs.argmax().item()], probs.max())\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "giant panda, panda, panda bear, coon bear, Ailuropoda melanoleuca\n",
            "gibbon, Hylobates lar\n",
            "nani\n",
            "gibbon, Hylobates lar tensor(1.0000, device='cuda:0', grad_fn=<MaxBackward1>)\n",
            "tensor([[[[ 0.5433,  0.4319,  0.3266,  ..., -1.3362, -1.2875, -1.2602],\n",
            "          [ 0.5445,  0.4227,  0.2898,  ..., -1.3935, -1.3659, -1.3326],\n",
            "          [ 0.5455,  0.3826,  0.2622,  ..., -1.4480, -1.4130, -1.4261],\n",
            "          ...,\n",
            "          [ 0.7797,  0.7744,  0.7888,  ...,  0.4260,  0.3888,  0.3484],\n",
            "          [ 0.7985,  0.7926,  0.8081,  ...,  0.4660,  0.4006,  0.3674],\n",
            "          [ 0.7798,  0.7827,  0.7839,  ...,  0.4869,  0.3985,  0.3527]],\n",
            "\n",
            "         [[ 1.1115,  0.9765,  0.7526,  ..., -1.0552, -0.9636, -0.9134],\n",
            "          [ 1.1068,  0.9616,  0.7147,  ..., -1.1121, -1.0396, -1.0086],\n",
            "          [ 1.0828,  0.9149,  0.6810,  ..., -1.1936, -1.1388, -1.1531],\n",
            "          ...,\n",
            "          [ 1.4762,  1.4679,  1.4784,  ...,  0.4270,  0.4380,  0.3813],\n",
            "          [ 1.4928,  1.4847,  1.5002,  ...,  0.4655,  0.4161,  0.3838],\n",
            "          [ 1.4737,  1.4768,  1.4754,  ...,  0.5059,  0.4131,  0.3654]],\n",
            "\n",
            "         [[ 1.4655,  1.3363,  1.1211,  ..., -0.6732, -0.5865, -0.5274],\n",
            "          [ 1.4599,  1.3188,  1.0794,  ..., -0.7217, -0.6809, -0.6419],\n",
            "          [ 1.4744,  1.2754,  1.0370,  ..., -0.7973, -0.7571, -0.7739],\n",
            "          ...,\n",
            "          [ 2.0880,  2.0829,  2.0788,  ...,  0.3068,  0.2837,  0.2334],\n",
            "          [ 2.0690,  2.0632,  2.0643,  ...,  0.3518,  0.3041,  0.2744],\n",
            "          [ 2.0323,  2.0540,  2.0418,  ...,  0.3925,  0.3050,  0.2640]]]],\n",
            "       device='cuda:0')\n",
            "gibbon, Hylobates lar tensor(1.0000, device='cuda:0', grad_fn=<MaxBackward1>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjiudlT9DHNP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "f8c11900-8eb2-4749-ff41-f9079a190ebf"
      },
      "source": [
        "!ps"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    PID TTY          TIME CMD\n",
            "      1 ?        00:00:00 run.sh\n",
            "      9 ?        00:00:06 node\n",
            "     24 ?        00:00:11 jupyter-noteboo\n",
            "    114 ?        00:00:00 tail\n",
            "    122 ?        00:01:48 python3\n",
            "   1281 ?        00:00:00 ps\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h67FESc5UF2P",
        "colab_type": "code",
        "outputId": "7d6de341-1ade-4695-bbb5-a75a2aa4399d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        }
      },
      "source": [
        "print(classes[probs.argmax().item()])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-ff0941b76fae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'probs' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGl6XTOFZy6R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "local = trans(perturbed_data.to('cpu')[0])\n",
        "trans(data.to('cpu')[0]).save('orig_doggo.jpg')\n",
        "local.save('doggo.jpg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaHK0EGNiqLE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3A9qOsiCHBI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "5f7b9170-8eb6-4227-e151-389085ffcf5e"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Nov 25 02:00:23 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.33.01    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60ubhb_ApULg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "f1a85a58-5ced-401e-a075-b87c657ce156"
      },
      "source": [
        "import os\n",
        "import h5py\n",
        "import numpy as np\n",
        "\n",
        "BASE_PATH = './'\n",
        "if not os.path.exists(BASE_PATH):\n",
        "    os.makedirs(BASE_PATH)\n",
        "DATA_PATH = BASE_PATH + 'tiny_imagenet/'\n",
        "\n",
        "!pwd\n",
        "!ls\n",
        "os.chdir(BASE_PATH)\n",
        "if not os.path.exists(DATA_PATH + 'train.h5'):\n",
        "    !wget https://courses.cs.washington.edu/courses/cse599g1/19au/files/homework2.tar\n",
        "    !tar -xvf homework2.tar\n",
        "    !ls\n",
        "    !rm homework2.tar"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "data\t   imagenet1000_clsidx_to_labels.txt  pgd_doggo.jpg  tiny_imagenet\n",
            "doggo.jpg  nanie.jpg\t\t\t      pt_util.py\n",
            "dog.jpg    orig_doggo.jpg\t\t      sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sie9s4uRry82",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data loader\n",
        "class H5Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, h5_file, transform=None):\n",
        "        # TODO Implement data loading.\n",
        "        f = h5py.File(h5_file, 'r')\n",
        "        self.images = f['images'][...]\n",
        "        self.labels = np.asarray(f['labels'][...], dtype='int64')\n",
        "        print(self.images.shape)\n",
        "        f.close()\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        # TODO Implement the length function\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # TODO implement the getitem function\n",
        "        # You should return a tuple of:\n",
        "        #    a torch tensor containing single image in CxHxW format and\n",
        "        #    the label as a single tensor scalar.\n",
        "        data = self.images[idx]\n",
        "        label = self.labels[idx]\n",
        "        if self.transform:\n",
        "            data = self.transform(data)\n",
        "        return (data, label)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZPv2rg25nGg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preprocess = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BslBTAdmr7yt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "39517b16-f1d0-4020-8854-0f89b03be491"
      },
      "source": [
        "data_train = H5Dataset(DATA_PATH + 'train.h5', transform=preprocess)\n",
        "print(len(data_train))\n",
        "data_test = H5Dataset(DATA_PATH + 'val.h5', transform=preprocess)\n",
        "print(len(data_test))\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100000, 64, 64, 3)\n",
            "100000\n",
            "(8000, 64, 64, 3)\n",
            "8000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "antQc-RkStRB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "8c9de192-51a3-4f36-f7e8-7b1a06cf3390"
      },
      "source": [
        "import time\n",
        "from torch.autograd import Variable\n",
        "#training\n",
        "# train = datasets.ImageNet('./data/', train=True, transform=preprocess, download=True)\n",
        "# train_loader = DataLoader(train, batch_size=128)\n",
        "use_cuda = True\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print('Using device', device)\n",
        "import multiprocessing\n",
        "print('num cpus:', multiprocessing.cpu_count())\n",
        "\n",
        "kwargs = {'num_workers': multiprocessing.cpu_count(),\n",
        "          'pin_memory': True} if use_cuda else {}\n",
        "\n",
        "model_training = torch.hub.load('pytorch/vision:v0.4.2', 'resnet18', pretrained=False)\n",
        "train_loader = torch.utils.data.DataLoader(data_train, batch_size=64,\\\n",
        "                                           shuffle=True, **kwargs)\n",
        "test_loader = torch.utils.data.DataLoader(data_test, batch_size=64, \\\n",
        "                                          shuffle=False, **kwargs)\n",
        "model_training.to(device)\n",
        "model_training.train()\n",
        "model.eval()\n",
        "optimizer_robust = optim.SGD(model_training.parameters(), lr=0.01)\n",
        "# optimizer_normal = optim.SGD(model.parameters(), lr=0.01)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "log_interval = 100\n",
        "model.to(device)\n",
        "try:\n",
        "    model_training.load_state_dict(torch.load('./mytraining.pt'))\n",
        "except Exception as e:\n",
        "    print(e)\n",
        "    print(\"there weren't any weights\")"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using device cuda\n",
            "num cpus: 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.4.2\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDIwjtaHTBKN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def proj_grad_desc(x, y, model, step_size=0.01, epsilon=4 * 1/255, steps=50, target=None):\n",
        "    adversary = x.clone().detach().requires_grad_(True).to(x.device)\n",
        "    max_diff = x + epsilon\n",
        "    min_diff = x - epsilon\n",
        "    for i in range(steps):\n",
        "        curr = adversary.clone().detach().requires_grad_(True).to(adversary.device)\n",
        "        output = model(curr)\n",
        "        loss = loss_fn(output, target.squeeze() if target else y.squeeze())\n",
        "        loss.backward()\n",
        "        with torch.no_grad():\n",
        "            curr_grad = curr.grad * step_size \n",
        "            if target:\n",
        "                adversary -= curr_grad\n",
        "            else:\n",
        "                adversary += curr_grad\n",
        "        adversary = torch.max(torch.min(adversary, max_diff), min_diff)\n",
        "        # adversary = adversary.clamp(0, 1)\n",
        "    return adversary.detach()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdUZOzW5iLRB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "92863c20-e6b2-4b1c-a2b4-c9313e963f02"
      },
      "source": [
        "try:\n",
        "\n",
        "    for epoch in range(start_epoch, 50):\n",
        "        model_training.train()\n",
        "        for batch_idx, (x, y) in enumerate(train_loader):\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "            x_adv = proj_grad_desc(x, y, model_training, step_size=0.01, epsilon=4 * 1/255)\n",
        "            optimizer_robust.zero_grad()\n",
        "            y_pred = model_training(x_adv)\n",
        "            loss = loss_fn(y_pred, y.squeeze())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            print('{} Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                time.ctime(time.time()),\n",
        "                epoch, batch_idx * len(x), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "            break\n",
        "        print(\"epoch {}: loss {}\".format(epoch, loss.item()))\n",
        "        model_training.eval()\n",
        "        correct_robust = 0\n",
        "        correct_normal = 0\n",
        "        test_loss_robust = 0\n",
        "        test_loss_normal = 0\n",
        "        for batch_idx, (x, y) in enumerate(test_loader):\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "            x_adv_robust = proj_grad_desc(x, y, model_training, step_size=0.01, epsilon=4 * 1/255)\n",
        "            x_adv_normal = proj_grad_desc(x, y, model, step_size=0.01, epsilon=4 * 1/255)                \n",
        "            optimizer_robust.zero_grad()\n",
        "            y_pred_robust = model_training(x_adv_robust)\n",
        "            y_pred_normal = model(x_adv_normal)\n",
        "            test_loss_on_robust = F.cross_entropy(y_pred_robust, y.squeeze(), reduction='elementwise_mean')\n",
        "            test_loss_on_normal = F.cross_entropy(y_pred_normal, y.squeeze(), reduction='elementwise_mean')\n",
        "            test_loss_robust += test_loss_on_robust\n",
        "            test_loss_normal += test_loss_on_normal\n",
        "            pred_robust = y_pred_robust.max(1)[1]\n",
        "            pred_normal = y_pred_normal.max(1)[1]\n",
        "\n",
        "            correct_mask = pred_robust.eq(y.view_as(pred_robust))\n",
        "            num_correct_robust = correct_mask.sum().item()\n",
        "            correct_robust += num_correct_robust\n",
        "\n",
        "            correct_mask = pred_normal.eq(y.view_as(pred_normal))\n",
        "            num_correct_normal = correct_mask.sum().item()\n",
        "            correct_normal += num_correct_normal\n",
        "\n",
        "            # if log_interval is not None and batch_idx % log_interval == 0:\n",
        "            print('{} Test: [{}/{} ({:.0f}%)]\\tRobust Loss: {:.6f}\\tNormal Loss: {:.6f}'.format(\n",
        "                time.ctime(time.time()),\n",
        "                batch_idx * len(x), len(test_loader.dataset),\n",
        "                100. * batch_idx / len(test_loader), test_loss_on_robust, test_loss_on_normal))\n",
        "        test_accuracy_robust = 100. * correct_robust / len(test_loader.dataset)\n",
        "        test_accuracy_normal = 100. * correct_normal / len(test_loader.dataset)\n",
        "        print(\"epoch {}: {}% robust accuracy, {}% normal accuracy\".format(epoch, test_accuracy_robust*100, test_accuracy_normal * 100))\n",
        "        pt_util.write_log(LOG_PATH, (train_losses, test_losses, test_accuracies))\n",
        "        model_training.save_state_dict('mytraining.pt')\n",
        "\n",
        "except KeyboardInterrupt as ke:\n",
        "    print('Interrupted')\n",
        "except:\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "finally:\n",
        "    torch.save(model_training.state_dict(),'./mytraining.pt')\n"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Nov 25 03:45:29 2019 Train Epoch: 0 [0/100000 (0%)]\tLoss: 7.105850\n",
            "epoch 0: loss 7.105849742889404\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:13: UserWarning: reduction='elementwise_mean' is deprecated, please use reduction='mean' instead.\n",
            "  warnings.warn(\"reduction='elementwise_mean' is deprecated, please use reduction='mean' instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mon Nov 25 03:45:32 2019 Test: [0/8000 (0%)]\tRobust Loss: 7.039098\tNormal Loss: 34.044773\n",
            "Mon Nov 25 03:45:34 2019 Test: [64/8000 (1%)]\tRobust Loss: 7.006715\tNormal Loss: 30.927504\n",
            "Mon Nov 25 03:45:36 2019 Test: [128/8000 (2%)]\tRobust Loss: 7.180508\tNormal Loss: 31.821222\n",
            "Mon Nov 25 03:45:38 2019 Test: [192/8000 (2%)]\tRobust Loss: 7.098144\tNormal Loss: 33.720978\n",
            "Mon Nov 25 03:45:41 2019 Test: [256/8000 (3%)]\tRobust Loss: 7.158152\tNormal Loss: 32.185883\n",
            "Mon Nov 25 03:45:43 2019 Test: [320/8000 (4%)]\tRobust Loss: 7.201855\tNormal Loss: 31.958851\n",
            "Mon Nov 25 03:45:45 2019 Test: [384/8000 (5%)]\tRobust Loss: 7.099662\tNormal Loss: 29.837330\n",
            "Mon Nov 25 03:45:47 2019 Test: [448/8000 (6%)]\tRobust Loss: 7.087817\tNormal Loss: 33.889820\n",
            "Mon Nov 25 03:45:49 2019 Test: [512/8000 (6%)]\tRobust Loss: 7.051002\tNormal Loss: 32.976254\n",
            "Mon Nov 25 03:45:52 2019 Test: [576/8000 (7%)]\tRobust Loss: 7.061491\tNormal Loss: 36.702423\n",
            "Mon Nov 25 03:45:54 2019 Test: [640/8000 (8%)]\tRobust Loss: 7.183473\tNormal Loss: 31.193056\n",
            "Mon Nov 25 03:45:56 2019 Test: [704/8000 (9%)]\tRobust Loss: 7.034740\tNormal Loss: 34.349354\n",
            "Mon Nov 25 03:45:58 2019 Test: [768/8000 (10%)]\tRobust Loss: 7.269932\tNormal Loss: 33.013306\n",
            "Mon Nov 25 03:46:00 2019 Test: [832/8000 (10%)]\tRobust Loss: 7.123200\tNormal Loss: 33.750313\n",
            "Mon Nov 25 03:46:02 2019 Test: [896/8000 (11%)]\tRobust Loss: 7.127724\tNormal Loss: 34.573662\n",
            "Mon Nov 25 03:46:05 2019 Test: [960/8000 (12%)]\tRobust Loss: 7.163791\tNormal Loss: 31.815664\n",
            "Mon Nov 25 03:46:07 2019 Test: [1024/8000 (13%)]\tRobust Loss: 7.210211\tNormal Loss: 34.385811\n",
            "Mon Nov 25 03:46:09 2019 Test: [1088/8000 (14%)]\tRobust Loss: 7.087837\tNormal Loss: 31.010895\n",
            "Mon Nov 25 03:46:11 2019 Test: [1152/8000 (14%)]\tRobust Loss: 7.137368\tNormal Loss: 30.512566\n",
            "Mon Nov 25 03:46:13 2019 Test: [1216/8000 (15%)]\tRobust Loss: 7.073616\tNormal Loss: 33.045479\n",
            "Mon Nov 25 03:46:16 2019 Test: [1280/8000 (16%)]\tRobust Loss: 7.170755\tNormal Loss: 35.430725\n",
            "Mon Nov 25 03:46:18 2019 Test: [1344/8000 (17%)]\tRobust Loss: 7.052744\tNormal Loss: 33.325043\n",
            "Mon Nov 25 03:46:20 2019 Test: [1408/8000 (18%)]\tRobust Loss: 6.959595\tNormal Loss: 33.602200\n",
            "Mon Nov 25 03:46:22 2019 Test: [1472/8000 (18%)]\tRobust Loss: 7.198586\tNormal Loss: 34.236420\n",
            "Mon Nov 25 03:46:24 2019 Test: [1536/8000 (19%)]\tRobust Loss: 7.121037\tNormal Loss: 34.289558\n",
            "Mon Nov 25 03:46:27 2019 Test: [1600/8000 (20%)]\tRobust Loss: 6.991167\tNormal Loss: 28.910286\n",
            "Mon Nov 25 03:46:29 2019 Test: [1664/8000 (21%)]\tRobust Loss: 7.043306\tNormal Loss: 31.137430\n",
            "Mon Nov 25 03:46:31 2019 Test: [1728/8000 (22%)]\tRobust Loss: 7.183064\tNormal Loss: 30.942858\n",
            "Mon Nov 25 03:46:33 2019 Test: [1792/8000 (22%)]\tRobust Loss: 7.121806\tNormal Loss: 33.556808\n",
            "Mon Nov 25 03:46:35 2019 Test: [1856/8000 (23%)]\tRobust Loss: 7.192099\tNormal Loss: 33.065521\n",
            "Mon Nov 25 03:46:38 2019 Test: [1920/8000 (24%)]\tRobust Loss: 7.218551\tNormal Loss: 35.054367\n",
            "Mon Nov 25 03:46:40 2019 Test: [1984/8000 (25%)]\tRobust Loss: 7.209575\tNormal Loss: 33.365864\n",
            "Mon Nov 25 03:46:42 2019 Test: [2048/8000 (26%)]\tRobust Loss: 7.242770\tNormal Loss: 31.128273\n",
            "Mon Nov 25 03:46:44 2019 Test: [2112/8000 (26%)]\tRobust Loss: 7.086966\tNormal Loss: 33.058189\n",
            "Mon Nov 25 03:46:46 2019 Test: [2176/8000 (27%)]\tRobust Loss: 7.110437\tNormal Loss: 34.917305\n",
            "Mon Nov 25 03:46:48 2019 Test: [2240/8000 (28%)]\tRobust Loss: 7.041571\tNormal Loss: 32.954441\n",
            "Mon Nov 25 03:46:51 2019 Test: [2304/8000 (29%)]\tRobust Loss: 7.159342\tNormal Loss: 34.363125\n",
            "Mon Nov 25 03:46:53 2019 Test: [2368/8000 (30%)]\tRobust Loss: 7.120605\tNormal Loss: 29.942635\n",
            "Mon Nov 25 03:46:55 2019 Test: [2432/8000 (30%)]\tRobust Loss: 7.061418\tNormal Loss: 32.485489\n",
            "Mon Nov 25 03:46:57 2019 Test: [2496/8000 (31%)]\tRobust Loss: 7.174620\tNormal Loss: 32.190060\n",
            "Mon Nov 25 03:46:59 2019 Test: [2560/8000 (32%)]\tRobust Loss: 7.013432\tNormal Loss: 33.422966\n",
            "Mon Nov 25 03:47:02 2019 Test: [2624/8000 (33%)]\tRobust Loss: 7.001518\tNormal Loss: 32.736538\n",
            "Mon Nov 25 03:47:04 2019 Test: [2688/8000 (34%)]\tRobust Loss: 7.195447\tNormal Loss: 31.078445\n",
            "Mon Nov 25 03:47:06 2019 Test: [2752/8000 (34%)]\tRobust Loss: 7.145885\tNormal Loss: 32.773376\n",
            "Mon Nov 25 03:47:08 2019 Test: [2816/8000 (35%)]\tRobust Loss: 7.119508\tNormal Loss: 33.203304\n",
            "Mon Nov 25 03:47:10 2019 Test: [2880/8000 (36%)]\tRobust Loss: 7.139767\tNormal Loss: 31.992691\n",
            "Mon Nov 25 03:47:13 2019 Test: [2944/8000 (37%)]\tRobust Loss: 7.129230\tNormal Loss: 31.087477\n",
            "Mon Nov 25 03:47:15 2019 Test: [3008/8000 (38%)]\tRobust Loss: 7.069837\tNormal Loss: 32.429287\n",
            "Mon Nov 25 03:47:17 2019 Test: [3072/8000 (38%)]\tRobust Loss: 7.274394\tNormal Loss: 28.459763\n",
            "Mon Nov 25 03:47:19 2019 Test: [3136/8000 (39%)]\tRobust Loss: 7.119791\tNormal Loss: 32.707844\n",
            "Mon Nov 25 03:47:21 2019 Test: [3200/8000 (40%)]\tRobust Loss: 7.064315\tNormal Loss: 33.618080\n",
            "Mon Nov 25 03:47:24 2019 Test: [3264/8000 (41%)]\tRobust Loss: 7.004378\tNormal Loss: 31.744526\n",
            "Mon Nov 25 03:47:26 2019 Test: [3328/8000 (42%)]\tRobust Loss: 7.206294\tNormal Loss: 35.898746\n",
            "Mon Nov 25 03:47:28 2019 Test: [3392/8000 (42%)]\tRobust Loss: 7.175253\tNormal Loss: 34.162838\n",
            "Mon Nov 25 03:47:30 2019 Test: [3456/8000 (43%)]\tRobust Loss: 7.149457\tNormal Loss: 33.916176\n",
            "Mon Nov 25 03:47:32 2019 Test: [3520/8000 (44%)]\tRobust Loss: 7.094728\tNormal Loss: 33.433456\n",
            "Mon Nov 25 03:47:34 2019 Test: [3584/8000 (45%)]\tRobust Loss: 6.956932\tNormal Loss: 34.802475\n",
            "Mon Nov 25 03:47:37 2019 Test: [3648/8000 (46%)]\tRobust Loss: 7.095439\tNormal Loss: 31.580196\n",
            "Mon Nov 25 03:47:39 2019 Test: [3712/8000 (46%)]\tRobust Loss: 7.013468\tNormal Loss: 31.686998\n",
            "Mon Nov 25 03:47:41 2019 Test: [3776/8000 (47%)]\tRobust Loss: 6.983296\tNormal Loss: 30.262465\n",
            "Mon Nov 25 03:47:43 2019 Test: [3840/8000 (48%)]\tRobust Loss: 7.039198\tNormal Loss: 32.948257\n",
            "Mon Nov 25 03:47:45 2019 Test: [3904/8000 (49%)]\tRobust Loss: 7.025958\tNormal Loss: 34.758553\n",
            "Mon Nov 25 03:47:48 2019 Test: [3968/8000 (50%)]\tRobust Loss: 7.168647\tNormal Loss: 31.080776\n",
            "Mon Nov 25 03:47:50 2019 Test: [4032/8000 (50%)]\tRobust Loss: 7.099028\tNormal Loss: 31.253502\n",
            "Mon Nov 25 03:47:52 2019 Test: [4096/8000 (51%)]\tRobust Loss: 7.118308\tNormal Loss: 33.974621\n",
            "Mon Nov 25 03:47:54 2019 Test: [4160/8000 (52%)]\tRobust Loss: 7.205664\tNormal Loss: 31.862009\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-101-8fb7e2a50819>\", line 28, in <module>\n",
            "    x_adv_robust = proj_grad_desc(x, y, model_training, step_size=0.01, epsilon=4 * 1/255)\n",
            "  File \"<ipython-input-90-3a87b2f1c1a3>\", line 7, in proj_grad_desc\n",
            "    output = model(curr)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 541, in __call__\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/root/.cache/torch/hub/pytorch_vision_v0.4.2/torchvision/models/resnet.py\", line 203, in forward\n",
            "    x = self.layer3(x)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 541, in __call__\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\", line 92, in forward\n",
            "    input = module(input)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 541, in __call__\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/root/.cache/torch/hub/pytorch_vision_v0.4.2/torchvision/models/resnet.py\", line 67, in forward\n",
            "    identity = self.downsample(x)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 541, in __call__\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\", line 92, in forward\n",
            "    input = module(input)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 541, in __call__\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/batchnorm.py\", line 81, in forward\n",
            "    exponential_average_factor, self.eps)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\", line 1670, in batch_norm\n",
            "    training, momentum, eps, torch.backends.cudnn.enabled\n",
            "RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 15.90 GiB total capacity; 15.02 GiB already allocated; 1.88 MiB free; 178.79 MiB cached)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Teu0uTKAPDot",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "5bda1602-c219-49c5-e7b6-e2ca711230db"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Nov 25 01:58:29 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.33.01    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   50C    P0    33W / 250W |  16259MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2o9Wa6DncMf4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}